[ { "title": "JMIV - Paper Submission", "url": "/posts/jmiv/", "categories": "Research, LRDE", "tags": "RDI, LRDE, JMIV", "date": "2021-09-20 00:00:00 +0200", "snippet": "Deep Learning, Morphological Layer, CNN, Grayscale Morphology,Research Paper, JMIVLearning Grayscale Mathematical Morphology with SmoothMorphological LayersAfter 6 months of working on the integration of mathematical morphology in aneural network, I was able with the help of my supervisors to make a submissionto the Journal of Mathematical Imaging and Vision (JMIV).This article has been accepted and published in May 2022 (Spinger Naturelink). Thepublisher also made it available on ResearchGate,with a full access for readers with institutional subscriptions.I have posted the abstract and the pictures are below.AbstractThe integration of mathematical morphology operations within convolutionalneural network architectures has received an increasing attention lately.However, replacing standard convolution layers by morphological layersperforming erosions or dilations is particularly challenging because the min andmax operations are not differentiable. P-convolution layers were proposed as apossible solution to this issue since they can act as smooth differentiableapproximation of min and max operations, yielding pseudo-dilation orpseudo-erosion layers. In a recent work, we proposed two novel morphologicallayers based on the same principle as the p-convolution, while circumventing itsprincipal drawbacks, and showcased their capacity to efficiently learn grayscalemorphological operators while raising several edge cases. In this work, wecomplete those previous results by thoroughly analyzing the behavior of theproposed layers and by investigating and settling the reported edge cases. Wealso demonstrate the compatibility of one of the proposed morphological layerswith binary morphological frameworks.Article Figures Top: illustration of the dilation of the pixel 13 (with red borders) with across-shaped binary structuring element. Bottom: illustration of the dilationof the same pixel 13 with a grayscale structuring element (Color figureonline)Top row: input image from the MNIST database and non-flat structuring elementw. Middle row: ℒMorph pseudo-dilation for p ∈ {0, 10, 20, 30}, and target dilation f ⊕ w. Bottom row: ℒMorph pseudo-erosion for p ∈ {0,  − 10,  − 20,  − 30} and target erosion f ⊖ w. Note that for the erosion,  − w is used in ℒMorph instead of w to approximate the the target f ⊖ w.Top row: input image from the MNIST database and non-flat structuring elementw. Middle row: 𝒮Morph pseudo-dilation for α ∈ {0, 5, 20, 30}, and target dilation f ⊕ w. Bottom row: 𝒮Morph pseudo-erosion for α ∈ {0,  − 5,  − 20,  − 30} and target erosion f ⊖ w. Note that for the erosion,  − w is used in 𝒮Morph instead of w to approximate the the target f ⊖ w.7×7 target grayscale structuring elements.All values range between 0 (deep blue) and1 (yellow).Network architecture used for the erosion/dilation scenarios. Blue blocks aretrainable units. A scenario is defined as the choice of ⊕ or ⊖ and one of the 6 targetstructuring elements in the upper path, and the choice of one layer among PConv, ℒMorph and 𝒮Morph in the lower path.Learned filter w, correspondingparameter p/α, RMSE betweenthe learned filter and the target structuring element, MSE training loss atconvergence and number of training epochs for PConv, ℒMorph and 𝒮Morphlayers on an erosion ⊖ task. Reported valuescorrespond to the average ± standard deviationover the 5 runs. Best (lowest) results are in bold.Learned filter w, correspondingparameter p/α, RMSE betweenthe learned filter and the target structuring element, MSE training loss atconvergence and number of training epochs for PConv, ℒMorph and 𝒮Morphlayers on a dilation ⊕ task. Reported valuescorrespond to the average ± standard deviationover the 5 runs. Best (lowest) results are in bold.Network architecture used for the opening/closing scenarios. Blue blocks aretrainable units. A scenario is defined as the choice of ∘ or • and one of the 6 targetstructuring elements in the upper path, and the choice of PConv, ℒMorph or 𝒮Morph forboth consecutive layers in the lower path.Learned filters wi, corresponding parameter pi/αiand RMSEi betweenthe learned filter and the target structuring element for both layers (i ∈ {1, 2}), MSE training loss atconvergence and number of training epochs for PConv, ℒMorph and 𝒮Morphlayers on an opening ∘ task. Best (lowest)results are in bold. Abnormal results are in red.Learned filters wi, corresponding parameter pi/αiand RMSEi betweenthe learned filter and the target structuring element for both layers (i ∈ {1, 2}), MSE training loss atconvergence and number of training epochs for PConv, ℒMorph and 𝒮Morphlayers on a closing • task. Best (lowest)results are in bold. Abnormal results are in red.Examples of network divergent behavior for PConv/cross7/• and ℒMorph/cross3/•scenarios, with average parameter values at convergence.Convergence of two consecutive 𝒮Morph layers ina closing • scenario, with corresponding valuesof α1 and α2. Target structuring elements arediamond3 (top row), cross7 (middle row) and disk2(bottom row). Layers are shown at initialization, 1%, 2%, 3%, 5%, 7%, 10%, 20%, 50% and 100% of total number of training epochs.Learned filters for opening ∘ and closing • operations for ℒMorph and 𝒮Morph forcross3 and disk2 in a 5 × 5spatial support, as well as disk3 in 9 × 9, 11 × 11 and 13 × 13 spatial supports.7×7 target binary structuring elements. Yellow(resp. blue) corresponds to boolean true (resp. false).Learned filter w and its clippedversion with associated colorbars, and quantitative metrics for a 𝒮Morph layer for binary erosion ⊖ (first row) and binary dilation ⊕ (second row) scenarios.Learned filter wi ∈ {1, 2} and its clipped version, and quantitative metrics for two 𝒮Morph layers for binary opening ∘ (first row) and binary closing • (second row) scenarios. Abnormal results are in red." }, { "title": "Detection of Venation Intersections in Bee Wings", "url": "/posts/imed/", "categories": "School Projects, Image Processing", "tags": "IMAGE, IMED, TIFO", "date": "2021-08-15 00:00:00 +0200", "snippet": "Image processing, Image DetectionProjectThe goal of this project was to find an algorithms pipeline that would get thevenation intersection detected. Microscopic images and some ground truth weregiven, but purposely not enough not for deep learning to be used. Here are a sample of given pictures with their ground truthChosen Solution Sato filter to highlight the venation Enhance and select highlighted venation with morphology Morphological reconstruction Skeletonize the result to ease corner detection Results at each step of the pipeline Corner detection with Harris corner detector Postprocessing to remove points too close from eachother (avoid duplicates) Result of raw corner detection and after post processing Final results for the 5 pictures with ground truth. The calculated average F-Scoreis 0.809" }, { "title": "Seminar - 15.07.2021 - Slides", "url": "/posts/seminar_slides/", "categories": "Research, LRDE, Seminar", "tags": "RDI, LRDE", "date": "2021-07-15 00:00:00 +0200", "snippet": "Keywords: Mathematical Morphology, Deep LearningThe PDF version can be found here" }, { "title": "Seminar - 15.07.2021 - Report", "url": "/posts/seminar_report/", "categories": "Research, LRDE, Seminar", "tags": "RDI, LRDE", "date": "2021-07-15 00:00:00 +0200", "snippet": "Mathematical Morphology, Deep LearningContextDuring my last year of study and after six months of working on my researchsubject, I wrote a complete report to expose my subject, explain it as best as Icould and describe my work.ReportThe PDF version can be found here" }, { "title": "Paper Presentation - Neural Ordinary Differential Equations", "url": "/posts/coder_pres/", "categories": "Research, Lectures Assignments & Work", "tags": "RDI, LRDE, CODER", "date": "2021-06-20 00:00:00 +0200", "snippet": "Deep Learning, Ordinary Differential Equations, ODE, Neural Ordinary Differential EquationsThe PDF version can be found here" }, { "title": "Lightning Talk - 04.05.2021", "url": "/posts/lightning_talk_3/", "categories": "Research, LRDE, Lightning Talks", "tags": "RDI, LRDE, LT", "date": "2021-05-04 00:00:00 +0200", "snippet": "Mathematical Morphology, Deep LearningThe PDF version can be found here" }, { "title": "Coding a Ray Tracer", "url": "/posts/isim/", "categories": "School Projects, Image Processing", "tags": "IMAGE, ISIM", "date": "2021-05-04 00:00:00 +0200", "snippet": "Ray Tracer, Ray Tracing, Image Modeling, Phong Model, Image RenderingSubjectFor this course project, the goal was to do something with a personalimplementation of a ray tracer.My base implementation was able to render objects in space like those spheres:ProjectI decided to implement the support of heightmaps,by creating them randomly with adiamond-squarealgorithm and discretizing their complex form into smaller ones (triangles) toease the ray tracing process.This pipeline can give this kind of output:Performances EnhancementThe problem for creating visualy attractive maps, is that a lot of triangles arerequired, and therefore the computation time increases a lot. To counter this, Ifound a trick to ignore most of the triangles during the ray tracing process.I decided to consider maps as a cuboids:Then, the cuboid could act as a hitbox and give interesting informations on theray that was launched during calculations, esentially where it was entering andexiting the cuboid:In the end, it reduces the number of triangles to check when searching whichobjects in the scene get intersected by the launched ray of light.I did some benchmarks, which showed that this method was indeed speeding up thecomputation process:Final ResultsFinally, I was able to have those results, with maps containing millions oftriangles:" }, { "title": "Classifying Pixels of Hyperspectral Images", "url": "/posts/iml/", "categories": "School Projects, Image Processing", "tags": "IMAGE, IML", "date": "2021-05-04 00:00:00 +0200", "snippet": "Hyperspectral Image, Classification, Machine LearningSubjectFor this project, we had to propose an image processing pipeline to classifypixels in hyperspectral images of crops. Two images and their ground truth weregiven: Those images have 200 and 204 spectral bands, respectively.Visualizing hyperspectral images in RGB is not complicated, the onlymanipulaiton needed is to select images at the corresponding spectralbands (30, 15 and 2 here)PipelinePreprocessingFirst of all, the more bands there is, the more the classifying process will belong and complicated; in this sense, the application of aPCA processingwhich led to dividing by (at least) 2 the number of dimensions by pixel (numberbands).ClassificationThen, we have tested a lot of classifying methods: SVMs, Random Forests, KMeans,Spectral Clustering, Hierarchical Clustering, MeanShift, Gaussian methods… Butthe two bests we came up with were the Nu-Support Vector Classification(NuSVC)and the Random ForestClassifier.During testing phase, we took every pixels into account, but we should haveonly taken pixels that were not from class 0 (null class, no crop, notclassified)The training set represents 80% of the data, the test set 20%. The training setis used for the training process, the test set is used after training andrepresents data that was never seen by the classifier before the end of itstraining. ACCURACY Training Set Test Set Mean (reconstuted image) NuSVC 0.855 0.785 0.841 Random Forest 0.999 0.738 0.947 NuSVC result Random Forest resultThe table shows that the NuSVC has slightly better results on data it has neverseen than the Random Forest, even though the latter performed better on thetraining set: the Random Forest overfits too much the data it sees.PostprocessingWhen we look at those resulting image, we can see holes in the fields, and spotsin the non classified regions: it really looks like noise on an image. So, weapplied mathematical morphology. To be more precised, we applied mathematicalmorphology operations class by class, to avoid fields to fuse together and keepthe non-classified delimitations in place. ACCURACY Reconstructed Image NuSVC 0.866 Random Forest 0.985 NuSVC final results Random Forest final resultsThe mean accuracy of both classifier increased with the postprocessing, but theone of the Random Forest really pumped. This final trick was really adapted toits output." }, { "title": "Barcode Detection on GPU", "url": "/posts/gpgpu/", "categories": "School Projects, Image Processing", "tags": "IMAGE, IRGPU", "date": "2021-04-12 00:00:00 +0200", "snippet": "CUDA, GPU Programming, Detection, Image ProcessingProjectImplementing Local Binary PatternsHitogramsalgorithm on GPU, then get the resulting images in a KMeans to extract a classcontaining all pixels related to the barcode.Various images were given, bellow an example of input image:LBPThe LBP is a simple yet very efficient textureoperator which labels the pixels of an image by thresholding the neighborhood ofeach pixel and considers the result as a binary number: LBP algorithm detailed (Image from Towards Data Science)HistogramsAfter calculating each pixel new value with LBP, the next step was to divide theimage in patches, and calculate the patches’ histograms. Each histogram is anentry to the following classification step. Histogram part detailed (Image from Towards Data Science)GPU ImplementationThe final strategy has been to launch only one kernel that would load a patch(16x16 pixels + borders needed to have neighboorhood) in shared memory and applythe LBP algorithm, finishing each thread job with a direct update of the histogram.This histogram update need an atomic operation, as multiple thread could bemodifying the same value at the same time. Therefore, the depicted method was abit slower than a more straight forward one, without the use of shared memory.However, the memory is managed more properly and the implementation of a strategylike parallel reduction to avoid atomics could be a great improvement.Classification ResultsResulting histograms are handed over to a pretrained KMeans (with clusters centersalready known) with arbitrary number of classes (here 16, which should be enough) Results of histograms classificationHere we can see in which classes each patch was classified. Testing withmultiple images, including some without barcode, the 12th class stands out as aquite good detection of the barcode." }, { "title": "Lightning Talk - 30.03.2021", "url": "/posts/lightning_talk_2/", "categories": "Research, LRDE, Lightning Talks", "tags": "RDI, LRDE, LT", "date": "2021-03-30 00:00:00 +0200", "snippet": "Mathematical Morphology, Deep LearningThe PDF version can be found here" }, { "title": "Lightning Talk - 02.03.2021", "url": "/posts/lightning_talk_1/", "categories": "Research, LRDE, Lightning Talks", "tags": "RDI, LRDE, LT", "date": "2021-03-02 00:00:00 +0100", "snippet": "Mathematical Morphology, Deep LearningThe PDF version can be found here" }, { "title": "Survey Presentation - Pooling Layers", "url": "/posts/biblio_survey_pres/", "categories": "Research, Lectures Assignments & Work", "tags": "RDI, LRDE, BIBLIO", "date": "2021-03-02 00:00:00 +0100", "snippet": "Deep Learning, Pooling Layer, SurveyThe PDF version can be found here" }, { "title": "Survey - Pooling Layers", "url": "/posts/biblio_survey/", "categories": "Research, Lectures Assignments & Work", "tags": "RDI, LRDE, BIBLIO", "date": "2021-03-02 00:00:00 +0100", "snippet": "Deep Learning, Pooling Layer, SurveyThe PDF version can be found here" }, { "title": "Paper Presentation - Detail-Preserving Pooling in Deep Networks", "url": "/posts/biblio_pres/", "categories": "Research, Lectures Assignments & Work", "tags": "RDI, LRDE, BIBLIO", "date": "2021-03-02 00:00:00 +0100", "snippet": "Deep Learning, Pooling LayerA short presentation on Detail-Preserving Pooling in DeepNetworks paper, fromFaraz Saeedan, Nicolas Weber, M. Goesele and S. RothThe PDF version can be found here" } ]
