<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="JMIV - Paper Submission" /><meta property="og:locale" content="en" /><meta name="description" content="1 2 Deep Learning, Morphological Layer, CNN, Grayscale Morphology, Research Paper, JMIV" /><meta property="og:description" content="1 2 Deep Learning, Morphological Layer, CNN, Grayscale Morphology, Research Paper, JMIV" /><link rel="canonical" href="https://kazoryah.github.io/posts/jmiv/" /><meta property="og:url" content="https://kazoryah.github.io/posts/jmiv/" /><meta property="og:site_name" content="Romain Hermary" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-09-20T00:00:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="JMIV - Paper Submission" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-03-07T18:44:12+01:00","datePublished":"2021-09-20T00:00:00+02:00","description":"1 2 Deep Learning, Morphological Layer, CNN, Grayscale Morphology, Research Paper, JMIV","headline":"JMIV - Paper Submission","mainEntityOfPage":{"@type":"WebPage","@id":"https://kazoryah.github.io/posts/jmiv/"},"url":"https://kazoryah.github.io/posts/jmiv/"}</script><title>JMIV - Paper Submission | Romain Hermary</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Romain Hermary"><meta name="application-name" content="Romain Hermary"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/favicons/android-chrome-512x512.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a style="font-variant-caps: small-caps;" href="/">Romain Hermary</a></div><div class="site-subtitle font-italic">PhD Student at Luxembourg University</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a><li class="nav-item"> <a href="/publications/" class="nav-link"> <i class="fa-fw fas fa-book-open ml-xl-3 mr-xl-3 unloaded"></i> <span>PUBLICATIONS</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/Kazoryah" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['romain.hermary','gmail.com'].join('@')" aria-label="email" class="order-4" > <i class="fas fa-envelope"></i> </a> <a href="https://www.linkedin.com/in/romain-hermary" aria-label="linkedin" class="order-5" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG â€º <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb" style="text-transform: uppercase; font-size: 1rem;"> <span> <a href="/"> Home </a> </span> <span>JMIV - Paper Submission</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>JMIV - Paper Submission</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Romain HERMARY </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Sep 20, 2021, 12:00 AM +0200" >Sep 20, 2021<i class="unloaded">2021-09-20T00:00:00+02:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Tue, Mar 7, 2023, 6:44 PM +0100" >Mar 7<i class="unloaded">2023-03-07T18:44:12+01:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="902 words">5 min read</span></div></div><div class="post-content"><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Deep Learning, Morphological Layer, CNN, Grayscale Morphology,
Research Paper, JMIV
</pre></table></code></div></div><p><br /><br /></p><center><h1> Learning Grayscale Mathematical Morphology with SmoothMorphological Layers</h1></center><p><br /><br /></p><p>After 6 months of working on the integration of mathematical morphology in a neural network, I was able with the help of my supervisors to make a submission to the Journal of Mathematical Imaging and Vision (<a href="https://springer.com/journal/10851">JMIV</a>).</p><p>This article has been accepted and published in May 2022 (<a href="https://link.springer.com/article/10.1007/s10851-022-01091-1?error=cookies_not_supported&amp;code=1a3cd712-4a95-43eb-87c6-5e20380959b0">Spinger Nature link</a>). The publisher also made it available on <a href="https://www.researchgate.net/publication/360606987_Learning_Grayscale_Mathematical_Morphology_with_Smooth_Morphological_Layers">Research Gate</a>, with a full access for readers with institutional subscriptions.</p><p>I have posted the abstract and the pictures are below.</p><p><br /><br /></p><h2 id="abstract">Abstract</h2><p>The integration of mathematical morphology operations within convolutional neural network architectures has received an increasing attention lately. However, replacing standard convolution layers by morphological layers performing erosions or dilations is particularly challenging because the min and max operations are not differentiable. P-convolution layers were proposed as a possible solution to this issue since they can act as smooth differentiable approximation of min and max operations, yielding pseudo-dilation or pseudo-erosion layers. In a recent work, we proposed two novel morphological layers based on the same principle as the p-convolution, while circumventing its principal drawbacks, and showcased their capacity to efficiently learn grayscale morphological operators while raising several edge cases. In this work, we complete those previous results by thoroughly analyzing the behavior of the proposed layers and by investigating and settling the reported edge cases. We also demonstrate the compatibility of one of the proposed morphological layers with binary morphological frameworks.</p><p><br /><br /></p><h2 id="article-figures">Article Figures</h2><p><a href="https://www.researchgate.net/figure/Top-illustration-of-the-dilation-of-the-pixel-13-with-red-borders-with-a-cross-shaped_fig1_360606987"> <img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig1/AS:1155814379261952@1652579030473/Top-illustration-of-the-dilation-of-the-pixel-13-with-red-borders-with-a-cross-shaped.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Top: illustration of the dilation of the pixel 13 (with red borders) with a cross-shaped binary structuring element. Bottom: illustration of the dilation of the same pixel 13 with a grayscale structuring element (Color figure online) </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Top-row-input-image-from-the-MNIST-database-and-non-flat-structuring-element-w-Middle_fig2_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig2/AS:1155814379270149@1652579030489/Top-row-input-image-from-the-MNIST-database-and-non-flat-structuring-element-w-Middle.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Top row: input image from the MNIST database and non-flat structuring element <span class="math inline"><em>w</em></span>. Middle row: <span class="math inline">â„’Morph</span> pseudo-dilation for <span class="math inline"><em>p</em>â€„âˆˆâ€„{0,â€†10,â€†20,â€†30}</span>, and target dilation <span class="math inline"><em>f</em>â€…âŠ•â€…<em>w</em></span>. Bottom row: <span class="math inline">â„’Morph</span> pseudo-erosion for <span class="math inline"><em>p</em>â€„âˆˆâ€„{0,â€†â€…âˆ’â€…10,â€†â€…âˆ’â€…20,â€†â€…âˆ’â€…30}</span> and target erosion <span class="math inline"><em>f</em>â€…âŠ–â€…<em>w</em></span>. Note that for the erosion, <span class="math inline">â€…âˆ’â€…<em>w</em></span> is used in <span class="math inline">â„’Morph</span> instead of <span class="math inline"><em>w</em></span> to approximate the the target <span class="math inline"><em>f</em>â€…âŠ–â€…<em>w</em></span>. </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Top-row-input-image-from-the-MNIST-database-and-non-flat-structuring-element-w-Middle_fig3_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig3/AS:1155814379257856@1652579030542/Top-row-input-image-from-the-MNIST-database-and-non-flat-structuring-element-w-Middle.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Top row: input image from the MNIST database and non-flat structuring element <span class="math inline"><em>w</em></span>. Middle row: <span class="math inline">ğ’®Morph</span> pseudo-dilation for <span class="math inline"><em>Î±</em>â€„âˆˆâ€„{0,â€†5,â€†20,â€†30}</span>, and target dilation <span class="math inline"><em>f</em>â€…âŠ•â€…<em>w</em></span>. Bottom row: <span class="math inline">ğ’®Morph</span> pseudo-erosion for <span class="math inline"><em>Î±</em>â€„âˆˆâ€„{0,â€†â€…âˆ’â€…5,â€†â€…âˆ’â€…20,â€†â€…âˆ’â€…30}</span> and target erosion <span class="math inline"><em>f</em>â€…âŠ–â€…<em>w</em></span>. Note that for the erosion, <span class="math inline">â€…âˆ’â€…<em>w</em></span> is used in <span class="math inline">ğ’®Morph</span> instead of <span class="math inline"><em>w</em></span> to approximate the the target <span class="math inline"><em>f</em>â€…âŠ–â€…<em>w</em></span>. </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/77documentclass12ptminimal-usepackageamsmath-usepackagewasysym_fig4_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig4/AS:1155814379266053@1652579030564/77documentclass12ptminimal-usepackageamsmath-usepackagewasysym.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> 7<span class="math inline">Ã—</span>7 target grayscale structuring elements. All values range between <span class="math inline">0</span> (deep blue) and <span class="math inline">1</span> (yellow). </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Network-architecture-used-for-the-erosion-dilation-scenarios-Blue-blocks-are-trainable_fig5_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig5/AS:1155814379274242@1652579030597/Network-architecture-used-for-the-erosion-dilation-scenarios-Blue-blocks-are-trainable.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Network architecture used for the erosion/dilation scenarios. Blue blocks are trainable units. A scenario is defined as the choice of <span class="math inline">âŠ•</span> or <span class="math inline">âŠ–</span> and one of the 6 target structuring elements in the upper path, and the choice of one layer among <span class="math inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>, <span class="math inline">â„’Morph</span> and <span class="math inline">ğ’®Morph</span> in the lower path. </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Learned-filter-w-corresponding-parameter-p-adocumentclass12ptminimal_fig6_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig6/AS:1155814379261954@1652579030617/Learned-filter-w-corresponding-parameter-p-adocumentclass12ptminimal.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Learned filter <span class="math inline"><em>w</em></span>, corresponding parameter <span class="math inline"><em>p</em>/<em>Î±</em></span>, RMSE between the learned filter and the target structuring element, MSE training loss at convergence and number of training epochs for <span class="math inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>, <span class="math inline">â„’Morph</span> and <span class="math inline">ğ’®Morph</span> layers on an erosion <span class="math inline">âŠ–</span> task. Reported values correspond to the average <span class="math inline">Â±</span> standard deviation over the 5 runs. Best (lowest) results are in bold. </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Learned-filter-w-corresponding-parameter-p-adocumentclass12ptminimal_fig7_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig7/AS:1155814379270157@1652579030644/Learned-filter-w-corresponding-parameter-p-adocumentclass12ptminimal.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Learned filter <span class="math inline"><em>w</em></span>, corresponding parameter <span class="math inline"><em>p</em>/<em>Î±</em></span>, RMSE between the learned filter and the target structuring element, MSE training loss at convergence and number of training epochs for <span class="math inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>, <span class="math inline">â„’Morph</span> and <span class="math inline">ğ’®Morph</span> layers on a dilation <span class="math inline">âŠ•</span> task. Reported values correspond to the average <span class="math inline">Â±</span> standard deviation over the 5 runs. Best (lowest) results are in bold. </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Network-architecture-used-for-the-opening-closing-scenarios-Blue-blocks-are-trainable_fig8_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig8/AS:1155814379257866@1652579030669/Network-architecture-used-for-the-opening-closing-scenarios-Blue-blocks-are-trainable.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Network architecture used for the opening/closing scenarios. Blue blocks are trainable units. A scenario is defined as the choice of <span class="math inline">âˆ˜</span> or <span class="math inline">â€¢</span> and one of the 6 target structuring elements in the upper path, and the choice of <span class="math inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>, <span class="math inline">â„’Morph</span> or <span class="math inline">ğ’®Morph</span> for both consecutive layers in the lower path. </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Learned-filters-widocumentclass12ptminimal-usepackageamsmath-usepackagewasysym_fig9_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig9/AS:1155814379266063@1652579030697/Learned-filters-widocumentclass12ptminimal-usepackageamsmath-usepackagewasysym.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Learned filters <span class="math inline"><em>w</em><sub><em>i</em></sub></span>, corresponding parameter <span class="math inline"><em>p</em><sub><em>i</em></sub>/<em>Î±</em><sub><em>i</em></sub></span> and RMSE<span class="math inline"><em></em><sub><em>i</em></sub></span> between the learned filter and the target structuring element for both layers (<span class="math inline"><em>i</em>â€„âˆˆâ€„{1,â€†2}</span>), MSE training loss at convergence and number of training epochs for <span class="math inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>, <span class="math inline">â„’Morph</span> and <span class="math inline">ğ’®Morph</span> layers on an opening <span class="math inline">âˆ˜</span> task. Best (lowest) results are in bold. Abnormal results are in red. </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Learned-filters-widocumentclass12ptminimal-usepackageamsmath-usepackagewasysym_fig10_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig10/AS:1155814379274251@1652579030724/Learned-filters-widocumentclass12ptminimal-usepackageamsmath-usepackagewasysym.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Learned filters <span class="math inline"><em>w</em><sub><em>i</em></sub></span>, corresponding parameter <span class="math inline"><em>p</em><sub><em>i</em></sub>/<em>Î±</em><sub><em>i</em></sub></span> and RMSE<span class="math inline"><em></em><sub><em>i</em></sub></span> between the learned filter and the target structuring element for both layers (<span class="math inline"><em>i</em>â€„âˆˆâ€„{1,â€†2}</span>), MSE training loss at convergence and number of training epochs for <span class="math inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>, <span class="math inline">â„’Morph</span> and <span class="math inline">ğ’®Morph</span> layers on a closing <span class="math inline">â€¢</span> task. Best (lowest) results are in bold. Abnormal results are in red. </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Examples-of-network-divergent-behavior-for-PConv-cross7-documentclass12ptminimal_fig11_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig11/AS:1155814379261965@1652579030780/Examples-of-network-divergent-behavior-for-PConv-cross7-documentclass12ptminimal.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Examples of network divergent behavior for <span class="math inline"><em>P</em><em>C</em><em>o</em><em>n</em><em>v</em></span>/<em>cross7</em>/<span class="math inline">â€¢</span> and <span class="math inline">â„’Morph</span>/<em>cross3</em>/<span class="math inline">â€¢</span> scenarios, with average parameter values at convergence. </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Convergence-of-two-consecutive-SMorphdocumentclass12ptminimal-usepackageamsmath_fig12_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig12/AS:1155814379270169@1652579030811/Convergence-of-two-consecutive-SMorphdocumentclass12ptminimal-usepackageamsmath.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Convergence of two consecutive <span class="math inline">ğ’®Morph</span> layers in a closing <span class="math inline">â€¢</span> scenario, with corresponding values of <span class="math inline"><em>Î±</em><sub>1</sub></span> and <span class="math inline"><em>Î±</em><sub>2</sub></span>. Target structuring elements are <em>diamond3</em> (top row), <em>cross7</em> (middle row) and <em>disk2</em> (bottom row). Layers are shown at initialization, <span class="math inline">1%</span>, <span class="math inline">2%</span>, <span class="math inline">3%</span>, <span class="math inline">5%</span>, <span class="math inline">7%</span>, <span class="math inline">10%</span>, <span class="math inline">20%</span>, <span class="math inline">50%</span> and <span class="math inline">100%</span> of total number of training epochs. </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Learned-filters-for-opening-documentclass12ptminimal-usepackageamsmath_fig13_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig13/AS:1155814379257876@1652579030842/Learned-filters-for-opening-documentclass12ptminimal-usepackageamsmath.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Learned filters for opening <span class="math inline">âˆ˜</span> and closing <span class="math inline">â€¢</span> operations for <span class="math inline">â„’Morph</span> and <span class="math inline">ğ’®Morph</span> for <em>cross3</em> and <em>disk2</em> in a <span class="math inline">5â€…Ã—â€…5</span> spatial support, as well as <em>disk3</em> in <span class="math inline">9â€…Ã—â€…9</span>, <span class="math inline">11â€…Ã—â€…11</span> and <span class="math inline">13â€…Ã—â€…13</span> spatial supports. </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/77documentclass12ptminimal-usepackageamsmath-usepackagewasysym_fig14_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig14/AS:1155814379266078@1652579030872/77documentclass12ptminimal-usepackageamsmath-usepackagewasysym.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> 7<span class="math inline">Ã—</span>7 target binary structuring elements. Yellow (resp. blue) corresponds to boolean <span class="smallcaps">true</span> (resp. <span class="smallcaps">false</span>). </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Learned-filter-w-and-its-clipped-version-with-associated-color-bars-and-quantitative_fig15_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig15/AS:1155814379274262@1652579030956/Learned-filter-w-and-its-clipped-version-with-associated-color-bars-and-quantitative.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Learned filter <span class="math inline"><em>w</em></span> and its clipped version with associated colorbars, and quantitative metrics for a <span class="math inline">ğ’®Morph</span> layer for binary erosion <span class="math inline">âŠ–</span> (first row) and binary dilation <span class="math inline">âŠ•</span> (second row) scenarios. </i></div><p><br /><br /></p><p><a href="https://www.researchgate.net/figure/Learned-filter-wi1-2documentclass12ptminimal-usepackageamsmath_fig16_360606987"><img data-proofer-ignore data-src="https://www.researchgate.net/publication/360606987/figure/fig16/AS:1155814379261988@1652579030998/Learned-filter-wi1-2documentclass12ptminimal-usepackageamsmath.png" /> </a></p><div class="alert alert-primary" role="alert"> <i> Learned filter <span class="math inline"><em>w</em><sub><em>i</em>â€„âˆˆâ€„{1,â€†2}</sub></span> and its clipped version, and quantitative metrics for two <span class="math inline">ğ’®Morph</span> layers for binary opening <span class="math inline">âˆ˜</span> (first row) and binary closing <span class="math inline">â€¢</span> (second row) scenarios. Abnormal results are in red. </i></div><p><br /><br /></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/research/'>Research</a>, <a href='/categories/lrde/'>LRDE</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/rdi/" class="post-tag no-text-decoration" >RDI</a> <a href="/tags/lrde/" class="post-tag no-text-decoration" >LRDE</a> <a href="/tags/jmiv/" class="post-tag no-text-decoration" >JMIV</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=JMIV - Paper Submission - Romain Hermary&url=https://kazoryah.github.io/posts/jmiv/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=JMIV - Paper Submission - Romain Hermary&u=https://kazoryah.github.io/posts/jmiv/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=JMIV - Paper Submission - Romain Hermary&url=https://kazoryah.github.io/posts/jmiv/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink('', 'Link copied successfully!')" data-toggle="tooltip" data-placement="top" title="Copy link"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/coder_pres/">Paper Presentation - Neural Ordinary Differential Equations</a><li><a href="/posts/biblio_pres/">Paper Presentation - Detail-Preserving Pooling in Deep Networks</a><li><a href="/posts/biblio_survey/">Survey - Pooling Layers</a><li><a href="/posts/biblio_survey_pres/">Survey Presentation - Pooling Layers</a><li><a href="/posts/jmiv/">JMIV - Paper Submission</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/lrde/">LRDE</a> <a class="post-tag" href="/tags/rdi/">RDI</a> <a class="post-tag" href="/tags/image/">IMAGE</a> <a class="post-tag" href="/tags/biblio/">BIBLIO</a> <a class="post-tag" href="/tags/lt/">LT</a> <a class="post-tag" href="/tags/coder/">CODER</a> <a class="post-tag" href="/tags/imed/">IMED</a> <a class="post-tag" href="/tags/iml/">IML</a> <a class="post-tag" href="/tags/irgpu/">IRGPU</a> <a class="post-tag" href="/tags/isim/">ISIM</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/lightning_talk_2/"><div class="card-body"> <span class="timeago small" >Mar 30, 2021<i class="unloaded">2021-03-30T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Lightning Talk - 30.03.2021</h3><div class="text-muted small"><p> Mathematical Morphology, Deep Learning The PDF version can be found here</p></div></div></a></div><div class="card"> <a href="/posts/lightning_talk_3/"><div class="card-body"> <span class="timeago small" >May 4, 2021<i class="unloaded">2021-05-04T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Lightning Talk - 04.05.2021</h3><div class="text-muted small"><p> Mathematical Morphology, Deep Learning The PDF version can be found here</p></div></div></a></div><div class="card"> <a href="/posts/seminar_report/"><div class="card-body"> <span class="timeago small" >Jul 15, 2021<i class="unloaded">2021-07-15T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Seminar - 15.07.2021 - Report</h3><div class="text-muted small"><p> Mathematical Morphology, Deep Learning Context During my last year of study and after six months of working on my research subject, I wrote a complete report to expose my subject, explain it as ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/imed/" class="btn btn-outline-primary" prompt="Older"><p>Detection of Venation Intersections in Bee Wings</p></a> <span class="btn btn-outline-primary disabled" prompt="Newer"><p>-</p></span></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> Â© 2023 <a href="https://github.com/username">Romain HERMARY</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/lrde/">LRDE</a> <a class="post-tag" href="/tags/rdi/">RDI</a> <a class="post-tag" href="/tags/image/">IMAGE</a> <a class="post-tag" href="/tags/biblio/">BIBLIO</a> <a class="post-tag" href="/tags/lt/">LT</a> <a class="post-tag" href="/tags/coder/">CODER</a> <a class="post-tag" href="/tags/imed/">IMED</a> <a class="post-tag" href="/tags/iml/">IML</a> <a class="post-tag" href="/tags/irgpu/">IRGPU</a> <a class="post-tag" href="/tags/isim/">ISIM</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://kazoryah.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-WFD9F2NVC7"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-WFD9F2NVC7'); }); </script>
